{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.transforms import Compose\n",
    "from tools.training_cycle import fit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot\n",
    "from tools.emnist_setup import emnist_setup\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "lr = 0.01\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "description of EMNIST\n",
    "\n",
    "\n",
    "splits ('byclass', 'bymerge', 'balanced', 'letters', 'digits', 'mnist')<br>\n",
    "'byclass':[0-9] [a-z] [A-Z], 814255 characters, 62 classes<br>\n",
    "'bymerge':[0-9] [a,b,d,e,f,g,h,n,q,r,t] [A-Z], 814255 characters, 47 classes<br>\n",
    "'balanced':[0-9] [a,b,d,e,f,g,h,n,q,r,t] [A-Z], 131600 characters, 47 classes<br>\n",
    "'letters':[A-Z], 145600 characters, 26 classes<br>\n",
    "'digits':[0-9], 280000 characters, 10 classes<br>\n",
    "'mnist':[0-9], 70000 characters, 10 classes<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = 'Pooling_Chebyshev_diagonal_rotational' # change to directory you want graphs in graphs/<dir>\n",
    "GRAPH_PATH = 'graphs' + '/' + DIRECTORY  \n",
    "DATA_PATH = \"data\"  # MNIST data folder\n",
    "FILE_PATH = ''  # path for saving data/model\n",
    "SPLIT = 'letters'  # choose which set of EMNIST to take\n",
    "DOWNLOAD_EMNIST = False  # set true if do not have data, downloads it\n",
    "LABEL_DICT, CLASSES, TARGET_TRANSFORM = emnist_setup(SPLIT)  # retrives constants based on split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_SIZE=784\n",
    "OUTP_SIZE=CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection\n",
    "from models.mixed1 import Mixed1\n",
    "from models.mixed2 import Mixed2\n",
    "from models.vpnn import Vpnn\n",
    "from models.vpnn_t import Vpnn_t\n",
    "from models.s_relu import S_ReLU\n",
    "\n",
    "model = Vpnn(INP_SIZE, OUTP_SIZE, hidden_layers=3,rotations=3,\n",
    "             chebyshev_M=2, diagonal_M=0.01, svd_u=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr, momentum=0.9)\n",
    "loss_funct = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes data from 2d image to 1d list\n",
    "# HxW -> L\n",
    "def flatten(x):\n",
    "    return x.view(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, data is 28x28 PIL images\n",
    "\n",
    "# list of functions that operate on data on load\n",
    "PREPROCESSING = Compose([torchvision.transforms.ToTensor(), flatten])\n",
    "\n",
    "train_ds = torchvision.datasets.EMNIST(\n",
    "      DATA_PATH, split=SPLIT, train=True, download=DOWNLOAD_EMNIST,\n",
    "      transform=PREPROCESSING, target_transform=TARGET_TRANSFORM\n",
    ")\n",
    "valid_ds = torchvision.datasets.EMNIST(\n",
    "      DATA_PATH, split=SPLIT, train=False, download=DOWNLOAD_EMNIST,\n",
    "      transform=PREPROCESSING, target_transform=TARGET_TRANSFORM\n",
    ")\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=bs, shuffle=True, pin_memory=True\n",
    ")\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size=bs * 2, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run training cycle\n",
    "data=fit(model, loss_funct, train_dl, valid_dl, opt, epochs, one_hot_size=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shows graphs of losses and accuracies in ui\n",
    "pyplot.plot(data['losses'])\n",
    "pyplot.title('losses')\n",
    "pyplot.xlabel('training batch')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(data['accs'])\n",
    "pyplot.title('accuracy on validation data')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.ylabel('% accuracy')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "ANNOT=False  # show values in each square, will get messy if too many values\n",
    "mat=0\n",
    "for x, y in valid_dl:\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    pred = model(x)\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    mat += confusion_matrix(y.numpy(), pred.cpu().detach().numpy(), labels=list(LABEL_DICT.keys()))\n",
    "sns.heatmap(mat.T, square=True, fmt='d',annot=ANNOT, cbar=False,\n",
    "           xticklabels=list(LABEL_DICT.values()), yticklabels=list(LABEL_DICT.values()))\n",
    "pyplot.xlabel('true label')\n",
    "pyplot.ylabel('predicted label')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.transforms import Compose\n",
    "from tools.training_cycle import fit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from tools.aclimdb_loader import aclimdb_load, test_review, review_to_words\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aclimdb data set<br>\n",
    "\n",
    "download at https://ai.stanford.edu/~amaas/data/sentiment/<br>\n",
    "expects folder aclImdb in DATA_PATH<br>\n",
    "needs files /imdb.vocab, /test/labeledBow.feat, train/labeledBow.feat<br>\n",
    "\n",
    "need to download nltk stopwords, does so automatically<br>\n",
    "\n",
    "data is returned from dataset as 1xINP_SIZE vector, with label 0 or 1<br>\n",
    "which contains the most common INP_SIZE words<br>\n",
    "label 0 = bad, label 1 = good<br>\n",
    "\n",
    "if want to keep stopwords use remove_stopwords=False in loader<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "lr = 0.1\n",
    "epochs = 10\n",
    "INP_SIZE = 5000  # number of words to accept\n",
    "OUTP_SIZE = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection\n",
    "from models.mixed1 import Mixed1\n",
    "from models.mixed2 import Mixed2\n",
    "from models.vpnn import Vpnn\n",
    "from models.vpnn_t import Vpnn_t\n",
    "from models.s_relu import S_ReLU\n",
    "\n",
    "model = Vpnn(INP_SIZE, OUTP_SIZE, hidden_layers=3,rotations=3,\n",
    "             chebyshev_M=2, diagonal_M=0.01, svd_u=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr, momentum=0.9)\n",
    "loss_funct = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"  # MNIST data folder\n",
    "FILE_PATH = ''  # path for saving data/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, data is 1xINP_SIZE vectors\n",
    "# warning: slow due to overhead expect 20s-1min to run\n",
    "\n",
    "# list of functions that operate on data on load\n",
    "PREPROCESSING = Compose([])\n",
    "\n",
    "# nmap is a dict that maps index -> word in input data\n",
    "# wmap is a dict that maps word -> index\n",
    "train_ds, valid_ds, nmap, wmap = aclimdb_load(DATA_PATH, INP_SIZE,\n",
    "                                        preprocessing=PREPROCESSING, remove_stopwords=True)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=bs, shuffle=True, pin_memory=True\n",
    ")\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size=bs * 2, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run training cycle\n",
    "data=fit(model, loss_funct, train_dl, valid_dl, opt, epochs, one_hot_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shows graphs of losses and accuracies in ui\n",
    "pyplot.plot(data['losses'])\n",
    "pyplot.title('losses')\n",
    "pyplot.xlabel('training batch')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(data['accs'])\n",
    "pyplot.title('accuracy on validation data')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.ylabel('% accuracy')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a custom review on model\n",
    "# warning: unsantized input. will not count punctuation, uppercase etc\n",
    "review = 'this was a good movie'\n",
    "test_review(review, wmap, INP_SIZE, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see word count in a given review\n",
    "review = 10\n",
    "review_to_words(valid_ds[review][0],nmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "mat=0\n",
    "for x, y in valid_dl:\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    pred = model(x)\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    mat += confusion_matrix(y.numpy(), pred.cpu().detach().numpy(), labels=list(range(2)))\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "           xticklabels='auto', yticklabels='auto')\n",
    "pyplot.ylim(2,0)\n",
    "pyplot.xlabel('true label')\n",
    "pyplot.ylabel('predicted label')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
